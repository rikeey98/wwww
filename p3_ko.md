# SoC RTL 검증 워크플로를 위한 AI 에이전트 기반 자동 할당 시스템

## 초록

SoC RTL 검증 워크플로는 설계 사양서와 검증 테스트 케이스 매칭 및 실패 발생 시 책임 엔지니어 할당의 수동 프로세스로 인해 심각한 효율성 문제에 직면하고 있다. 본 논문은 RTL 설계 사양서와 검증 테스트 사양서를 자동으로 매칭하고 실패 시나리오에서 적절한 팀원을 지능적으로 할당하는 AI 에이전트 기반 시스템을 제시한다. 제안 시스템은 두 개의 전문화된 AI 에이전트를 사용한다: 설계 의도와 검증 목표를 연관시키는 사양서 매칭 에이전트와 실패 컨텍스트 및 팀 전문성 매트릭스를 기반으로 책임 엔지니어를 식별하는 할당 에이전트. 우리의 예비 구현은 자동화된 사양서 매칭과 지능적 작업 할당을 실증하며, 검증 워크플로에서 명확한 책임 체계를 구축하면서 수동 조정 오버헤드를 줄인다. 이 접근법은 임시적인 검증 관리를 팀 조정을 향상시키고 실패 해결을 가속화하는 체계적이고 자동화된 프로세스로 변환한다.

**키워드:** AI 에이전트, SoC 검증, 자동화 할당, 사양서 매칭

## 1. 서론

현대 SoC RTL 검증은 기능적 사양서를 작성하는 설계 팀과 해당 테스트 케이스를 개발하는 검증 팀 간의 복잡한 조정을 포함한다. 현재 워크플로는 설계 사양서와 검증 테스트 케이스 간의 연결을 설정하는 수동 프로세스에 크게 의존하며, 이로 인해 실패 발생 시 모호한 책임 체계가 발생한다. 엔지니어들은 일반적으로 특정 실패를 해결할 적절한 팀원을 식별하는 데 2-6시간을 소요하며, 종종 명확한 소유권 없이 팀 간에 이슈가 전달되는 핑퐁 효과를 초래한다.

검증 프로세스는 해결을 위해 도메인 전문성이 필요한 수많은 실패 시나리오를 생성하지만, 올바른 책임자를 결정하는 것은 실패 로그, 사양서 문서, 팀 책임 매트릭스의 수동 분석을 포함한다. 이러한 수동 조정은 해결을 지연시키고 전체 검증 효율성을 감소시키는 병목을 야기한다.

본 논문은 사양서 매칭 프로세스를 자동화하고 실패 시나리오에서 책임 엔지니어의 지능적 할당을 제공하는 AI 에이전트 기반 시스템을 제안한다. 우리의 접근법은 두 가지 중요한 자동화 지점에 초점을 맞춘다: 설계 사양서와 검증 테스트 케이스 간의 명확한 매핑 설정, 그리고 실패 발생 시 적절한 팀원의 자동 식별.

## 2. 시스템 아키텍처

### 2.1 전체 프레임워크

제안 시스템은 RTL 설계 사양서, 검증 테스트 사양서, 팀 책임 매트릭스, 실패 로그 데이터베이스를 포함하는 통합 데이터 환경 내에서 작동한다. 두 개의 전문화된 AI 에이전트가 조정하여 사양서 관리 및 실패 할당 프로세스를 자동화한다.

```
[RTL 설계 사양서] ──┐
                   ├─→ [사양서 매칭 에이전트] ──→ [매핑 데이터베이스]
[검증 사양서] ──────┘                                │
                                                   │
[실패 감지] ──→ [할당 에이전트] ←─────────────────────┘
                    │
                    ▼
              [자동화된 알림]
            (JIRA/이메일/사내 메신저)
```

### 2.2 사양서 매칭 에이전트

사양서 매칭 에이전트는 RTL 설계 사양서와 검증 테스트 사양서를 분석하여 의미적 상관관계와 기능적 매핑을 설정한다. 이 에이전트는 사양서 문서를 처리하여 설계 블록, 기능적 요구사항, 인터페이스 정의를 식별한 다음, 이러한 요소들을 해당하는 검증 테스트 목표 및 커버리지 대상과 연관시킨다.

에이전트는 자연어 처리 기술을 사용하여 사양서 의도를 이해하고 어떤 검증 테스트가 특정 설계 기능에 해당하는지 명확하게 정의하는 구조화된 매핑을 생성한다. 이러한 매핑은 후속 실패 할당 결정의 기초를 형성한다.

### 2.3 할당 에이전트

할당 에이전트는 실패 로그, 설정된 사양서 매핑, 팀 책임 매트릭스를 활용하여 특정 실패를 해결할 적절한 엔지니어를 식별한다. 검증 실패가 발생하면, 이 에이전트는 실패 특성을 분석하고, 사양서 매핑을 통해 영향 받는 설계 도메인을 결정하며, 팀 전문성 데이터베이스를 참조하여 최적의 할당 대상을 식별한다.

에이전트는 엔지니어 전문 영역, 현재 워크로드, 프로젝트 우선순위, 에스컬레이션 정책을 포함한 여러 요소를 고려하여 정보에 입각한 할당 결정을 내린다. 투명성을 위해 신뢰도 점수와 지원 근거가 포함된 할당 권장사항을 생성한다.

## 3. 구현 접근법

### 3.1 데이터 통합

시스템은 구조화된 설계 사양서 저장소, 검증 테스트 데이터베이스, 동적 팀 할당 매트릭스를 포함한 이질적인 데이터 소스를 통합한다. 데이터 표준화는 다양한 사양서 형식과 팀 관리 시스템에 걸친 일관된 처리를 보장한다.

### 3.2 에이전트 구현

두 에이전트 모두 도메인별 프롬프팅 전략과 함께 대형 언어 모델 능력을 활용한다. 사양서 매칭 에이전트는 의미적 유사도 분석과 기능 블록 상관관계 기술을 사용하며, 할당 에이전트는 전문성 매칭과 워크로드 최적화를 기반으로 한 다중 기준 의사결정을 구현한다.

### 3.3 알림 통합

시스템은 이슈 추적을 위한 JIRA, 공식 알림을 위한 이메일 시스템, 즉시 알림을 위한 사내 메시징 플랫폼을 포함한 기존 워크플로 도구와 통합된다. 알림에는 실패 특성, 할당된 책임, 관련 사양서 참조에 대한 상황별 정보가 포함된다.

## 4. 예비 결과

### 4.1 사양서 매칭 정확도

50개의 RTL 설계 사양서와 200개의 해당 검증 테스트 케이스를 사용한 초기 평가는 유망한 매칭 능력을 보여준다. 사양서 매칭 에이전트는 설계 기능과 검증 목표 간의 관계를 식별하는 데 합리적인 상관관계 정확도를 달성한다.

### 4.2 할당 효과성

과거 실패 시나리오를 사용한 예비 테스트는 실패 특성과 팀 전문성 프로파일을 기반으로 적절한 팀원을 식별하는 할당 에이전트의 능력을 보여준다. 시스템은 할당 품질을 유지하면서 수동 할당 시간을 몇 시간에서 몇 분으로 줄인다.

### 4.3 프로세스 개선

초기 배포는 조정 오버헤드의 상당한 감소와 책임 할당의 명확성 향상을 나타낸다. 엔지니어들은 향상된 워크플로 효율성과 실패 소유권의 모호성 감소를 보고한다.

## 5. 향후 연구

향후 개발은 더 정교한 사양서 분석과 향상된 할당 최적화를 포함한 에이전트 능력 확장에 초점을 맞출 것이다. 우리는 과거 성공 패턴과 엔지니어 피드백을 기반으로 매칭 정확도를 개선하는 학습 메커니즘을 구현할 계획이다.

추가 작업은 더 광범위한 검증 자동화 시스템과의 통합 및 복잡한 조정과 할당 관리를 요구하는 다른 엔지니어링 도메인으로의 확장을 탐구할 것이다.

## 6. 결론

본 논문은 SoC RTL 검증 워크플로에서 사양서 매칭과 엔지니어 할당을 자동화하기 위한 AI 에이전트 기반 시스템을 제시한다. 제안된 접근법은 인간의 감독과 의사결정 권한을 유지하면서 지능적 자동화를 통해 중요한 조정 문제를 해결한다.

우리의 예비 구현은 자동화된 사양서 상관관계와 지능적 작업 할당의 실현 가능성을 보여준다. 시스템은 명확한 책임 체계를 구축하여 실패 해결을 가속화하면서 더 효율적인 검증 관리의 기초를 제공한다.

이 연구는 검증 워크플로 관리를 위한 실용적인 자동화 솔루션에 기여하면서 엔지니어링 조정 작업에서 AI 에이전트의 더 광범위한 응용을 위한 프레임워크를 만든다. 향후 연구는 이러한 능력을 포괄적인 검증 프로세스 자동화로 확장할 것이다.

## 참고문헌

[1] P. Lewis et al., "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks," Advances in Neural Information Processing Systems, vol. 33, pp. 9459-9474, 2020.

[2] Y. Zhang et al., "AutoCodeRover: Autonomous Program Improvement," Computing Research Repository, pp. 1592-1604, 2024.

[3] W. Guan et al., "LogLLM: Log-based Anomaly Detection Using Large Language Models," arXiv:2411.08561v1, 2024.

[4] C. E. Jimenez et al., "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?" International Conference on Learning Representations, arXiv:2310.06770, 2023.
